import requests
import argparse
import random

# Define os argumentos do script
parser = argparse.ArgumentParser()
parser.add_argument("-l", "--url_list", help="Nome do arquivo que contém as URLs", required=True)
args = parser.parse_args()

# Abre o arquivo e lê as URLs
with open(args.url_list) as f:
    urls = [line.rstrip() for line in f]

# Cria um dicionário para armazenar as URLs únicas
unique_urls = {}

# Percorre as URLs e identifica as duplicatas com base no padrão da URL
for url in urls:
    pattern = url.split('?')[0] # Pega o padrão da URL, ignorando os parâmetros
    if pattern not in unique_urls:
        unique_urls[pattern] = url # Armazena a primeira ocorrência do padrão

# Verifica quais URLs estão online e armazena em uma lista
online_urls = []
for url in unique_urls.values():
    try:
        response = requests.get(url)
        if response.status_code == 200:
            online_urls.append(url)
    except:
        pass

# Escolhe aleatoriamente uma URL online e imprime na tela
if online_urls:
    chosen_url = random.choice(online_urls)
    print(chosen_url)
else:
    print("Nenhuma URL está online")
