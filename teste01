from collections import Counter
import math

def entropy(s):
    p, lns = Counter(s), float(len(s))
    return -sum( count/lns * math.log(count/lns, 2) for count in p.values())

def remove_duplicates(urls, threshold=3.0):
    unique_urls = []
    for url in urls:
        url_entropy = entropy(url)
        if not any(abs(entropy(existing_url) - url_entropy) <= threshold for existing_url in unique_urls):
            unique_urls.append(url)
    return unique_urls

urls = [
    "https://www.okx.com/de/account/register?action=header_register_btn",
    "https://www.okx.com/tr/account/register?action=header_register_btn",
    "https://www.okx.com/pl/account/register?action=header_register_btn",
    "https://www.okx.com/ua/account/register?action=header_register_btn",
    "https://www.okx.com/it/earn/dual?from=home",
    "https://www.okx.com/hk/earn/dual?from=home",
    "https://www.okx.com/pl/earn/dual?from=home",
    "https://www.okx.com/id/earn/dual?from=home"
]

unique_urls = remove_duplicates(urls)
print(unique_urls)
